{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGRYeiZwf66H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import platform\n",
        "import gc\n",
        "import sys\n",
        "import argparse\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from joblib import Parallel, delayed\n",
        "import re\n",
        "import random\n",
        "import requests\n",
        "import urllib.request\n",
        "import json\n",
        "from copy import deepcopy\n",
        "import copy\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "import transformers\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, TrainingArguments, AutoModelForCausalLM, BitsAndBytesConfig, PreTrainedTokenizerFast\n",
        "from datasets import load_dataset\n",
        "from trl import DPOTrainer, SFTTrainer\n",
        "import bitsandbytes as bnb\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, PeftModel\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "from typing import Optional, Dict, Sequence\n",
        "from Korpora import Korpora\n",
        "from Korpora import KowikiTextKorpus, KorNLIKorpus\n",
        "# from googletrans import Translator\n",
        "from dask import bag, diagnostics\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_system_specs():\n",
        "    # Check if CUDA is available\n",
        "    is_cuda_available = torch.cuda.is_available()\n",
        "    print(\"CUDA Available:\", is_cuda_available)\n",
        "# Get the number of available CUDA devices\n",
        "    num_cuda_devices = torch.cuda.device_count()\n",
        "    print(\"Number of CUDA devices:\", num_cuda_devices)\n",
        "    if is_cuda_available:\n",
        "        for i in range(num_cuda_devices):\n",
        "            # Get CUDA device properties\n",
        "            device = torch.device('cuda', i)\n",
        "            print(f\"--- CUDA Device {i} ---\")\n",
        "            print(\"Name:\", torch.cuda.get_device_name(i))\n",
        "            print(\"Compute Capability:\", torch.cuda.get_device_capability(i))\n",
        "            print(\"Total Memory:\", torch.cuda.get_device_properties(i).total_memory, \"bytes\")\n",
        "    # Get CPU information\n",
        "    print(\"--- CPU Information ---\")\n",
        "    print(\"Processor:\", platform.processor())\n",
        "    print(\"System:\", platform.system(), platform.release())\n",
        "    print(\"Python Version:\", platform.python_version())\n",
        "print_system_specs()"
      ],
      "metadata": {
        "id": "4Ud6_Bfzf-Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Rbn1Hszqf_P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D1Es_V3JgARF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load to Data\n",
        "data_location = '/content/drive/MyDrive/llm'\n",
        "data_path = Path(data_location)\n",
        "\n",
        "train = pd.read_csv(data_path / 'train.csv')"
      ],
      "metadata": {
        "id": "fSaYUuN0gBP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open API Rule"
      ],
      "metadata": {
        "id": "c-Va9FmtgFrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Papago translator\n",
        "\n",
        "def back_translate_papago(sentence, lang, PROB = 1):\n",
        "  CLIENT_ID, CLIENT_SECRET = # 클라이언트 ID 및 클라이언트 SECRET 작성\n",
        "\n",
        "  url = 'https://openapi.naver.com/v1/papago/n2mt'\n",
        "\n",
        "  headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'X-Naver-Client-Id': CLIENT_ID,\n",
        "    'X-Naver-Client-Secret': CLIENT_SECRET\n",
        "  }\n",
        "\n",
        "  translated = {'source': 'ko', 'target': lang, 'text': sentence}\n",
        "\n",
        "  response = requests.post(url, json.dumps(translated), headers = headers)\n",
        "\n",
        "  back_translated = {'source': lang, 'target': 'ko', 'text': str(response.json()['message']['result']['translatedText'])}\n",
        "\n",
        "  back_response = requests.post(url, json.dumps(back_translated), headers = headers)\n",
        "\n",
        "  translated_back = str(back_response.json()['message']['result']['translatedText'])\n",
        "\n",
        "  return translated_back\n",
        "\n",
        "# parallel apply\n",
        "\n",
        "def back_translate_parallel1(dataset, translate_column, lang, save_file = True):\n",
        "  translate_bag = bag.from_sequence(dataset[translate_column].tolist()).map(lambda x: back_translate_papago(x, lang = lang))\n",
        "\n",
        "  with diagnostics.ProgressBar():\n",
        "    bag_completed = translate_bag.compute()\n",
        "\n",
        "  dataset[f'{translate_column}_tranlsate'] = bag_completed\n",
        "\n",
        "  return dataset\n",
        "\n",
        "def back_translate_parallel2(dataset, translate_column, lang, save_file = True):\n",
        "  try:\n",
        "    dataset[f'{translate_column}_translate'] = dataset[f'{translate_column}'].progress_apply(lambda x: back_translate_papago(x, 'en'))\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error occurred: {str(e)}\")\n",
        "    if save_file:\n",
        "      save_path = '/content/back_translate.csv'\n",
        "      if not os.path.exists(f'{save_path}'):\n",
        "        dataset.to_csv(f'{save_path}', index = False, mode = 'w', encoding = 'utf-8-sig')\n",
        "      else:\n",
        "        dataset.to_csv(f'{save_path}', index = False, mode = 'a', encoding = 'utf-8-sig')\n",
        "\n",
        "  return dataset\n",
        "\n",
        "# Cumulative save\n",
        "\n",
        "def cumulative_storage(df, route):\n",
        "  if not os.path.exists(f'{route}'):\n",
        "    df.to_csv(f'{route}', idnex = False, mode = 'w', encoding = 'utf-8-sig')\n",
        "  else:\n",
        "    df.to_csv(f'{route}', index = False, mode = 'a', encoding = 'utf-8-sig')"
      ],
      "metadata": {
        "id": "dxgJYoshgFGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crawling rule"
      ],
      "metadata": {
        "id": "2liwZdiPgKVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo add-apt-repository ppa:saiarcot895/chromium-beta\n",
        "!sudo apt remove chromium-browser\n",
        "!sudo snap remove chromium\n",
        "!sudo apt install chromium-browser\n",
        "\n",
        "!pip3 install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin/\n",
        "\n",
        "sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')"
      ],
      "metadata": {
        "id": "ys5GF2nrgMK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service"
      ],
      "metadata": {
        "id": "i587ail-gQsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Papago Translator Crawling Rule\n",
        "\n",
        "def back_translate_papago(sentence, lang):\n",
        "  options = webdriver.ChromeOptions()\n",
        "  options.add_argument('--headless')\n",
        "  options.add_argument('--no-sandbox')\n",
        "  options.add_argument('--disable-dev-shm-usage')\n",
        "  # webdriver_service = Service('/usr/bin/chromedriver')\n",
        "  # driver = webdriver.Chrome(service = webdriver_service, options = options)\n",
        "  driver = webdriver.Chrome(options = options)\n",
        "  papago_url = 'https://papago.naver.com/'\n",
        "  driver.get(papago_url)\n",
        "  time.sleep(5)\n",
        "\n",
        "  driver.find_element(By.CSS_SELECTOR, '#txtSource').send_keys(sentence) # #txtSource\n",
        "  driver.find_element(By.CSS_SELECTOR, '#root > div > div.wrap___1rX6i.rwd.rwd___3Qe-c.banner_active___3MQbf > section > div > div:nth-child(1) > div:nth-child(3) > div > div.lang_select___3h6b5 > button').click() # button#btnTranslate\n",
        "  time.sleep(5)\n",
        "\n",
        "  driver.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[1]/section/div/div[1]/div[2]/div/div[2]/button').click()\n",
        "  time.sleep(5)\n",
        "\n",
        "  back_translated = driver.find_element(By.CSS_SELECTOR, '#txtTarget > span').text # targetEditArea#txtTarget\n",
        "  time.sleep(5)\n",
        "\n",
        "  driver.close()\n",
        "  driver.quit()\n",
        "\n",
        "  return back_translated\n",
        "\n",
        "def back_translate_parallel2(dataset, translate_column, lang, save_file = True):\n",
        "  try:\n",
        "    dataset[f'{translate_column}_translate'] = dataset[f'{translate_column}'].progress_apply(lambda x: back_translate_papago(x, 'en'))\n",
        "    dataset.to_csv(f'{save_path}', index = False, mode = 'w') # , encoding = 'utf-8-sig'\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error occurred: {str(e)}\")\n",
        "    if save_file:\n",
        "      save_path = '/content/back_translate.csv'\n",
        "      if not os.path.exists(f'{save_path}'):\n",
        "        dataset.to_csv(f'{save_path}', index = False, mode = 'w') # , encoding = 'utf-8-sig'\n",
        "      else:\n",
        "        dataset.to_csv(f'{save_path}', index = False, mode = 'a') # , encoding = 'utf-8-sig'\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "09tC1pCsgSet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_aug = back_translate_parallel2(dataset = train, translate_column = '답변_1', lang = 'en', save_file = True)"
      ],
      "metadata": {
        "id": "yPyNHTLQgV5f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}